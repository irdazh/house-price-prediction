{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e0ee2e",
   "metadata": {},
   "source": [
    "# AHP Basic Modeling\n",
    "**Preprocess**\n",
    "- I drop 4 features with missing values more than 80%\n",
    "- I use pipeline to preprocess the data, including feature engineering (tho kinda useless for ensemble tree models), impute missing value using new class (None) for categorical data and median value for numeric data\n",
    "- Yeah, I guess I did overlook for categorical data encoded in int64 data types, but for now, let them be (there's not much difference since not many variables have missing values)\n",
    "- I use StandardScaler for scaling numeric features (how about RobustScaler?) (I don't have to do it for tree models tho)\n",
    "- I use OrdinalEncoder for categorical data (better than one hot, less demanding in complexity)\n",
    "\n",
    "**Modeling**\n",
    "- As for modeling, I use 4 linear models, 1 neighbour model (what does it called?), and 4 tree models\n",
    "- In here, we will do basic model with and without feature engineering and compare both of them.\n",
    "- I use 5-fold cross validation for evaluating the model\n",
    "- For evaluation metrics, I use MSLE (root mean squared log error) as a main metric (which I make from scratch, cause for some reason the default result in NaN), and RMSE (root mean squared error) as a helper metric to understand the model better\n",
    "- I guess that's all for today's briefing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "# from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, OrdinalEncoder, OneHotEncoder, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, root_mean_squared_log_error, root_mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5cad14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "3         Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0       0      2    2008        WD         Normal     208500  \n",
       "1       0      5    2007        WD         Normal     181500  \n",
       "2       0      9    2008        WD         Normal     223500  \n",
       "3       0      2    2006        WD        Abnorml     140000  \n",
       "4       0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df.drop(columns=['Id'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b3bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SalePrice']\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "\n",
    "# remove high missing cols\n",
    "X.drop('PoolQC MiscFeature Alley Fence'.split(), axis=1, errors='ignore')\n",
    "\n",
    "num_var = X.select_dtypes(include='number').columns\n",
    "ord_var = X.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d50001b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering from kaggle's learn\n",
    "# rooms' spaciousness, outside area, building type x ground area\n",
    "def feature_eng(df):\n",
    "  X = df.copy()\n",
    "\n",
    "  outside = \"WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch\".split()\n",
    "\n",
    "  X[\"Spaciousness\"] = (X[\"1stFlrSF\"]+X[\"2ndFlrSF\"])/X[\"TotRmsAbvGrd\"].replace(0, np.nan)\n",
    "  X[\"TotalOutsideSF\"] = X[outside].sum(axis=1)\n",
    "  X[\"PorchTypes\"] = X[outside].gt(0).sum(axis=1)\n",
    "  \n",
    "  # must use custom transformer: GroupMeanEncoder\n",
    "  # X[\"MedNhbdArea\"] = X.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n",
    "\n",
    "  # it's prone to error, and should use uhm. \n",
    "  X3 = pd.get_dummies(X.BldgType, prefix=\"Bldg\", )\n",
    "  X3 = X3.mul(X.GrLivArea, axis=0)\n",
    "  \n",
    "  return pd.concat([X, X3], axis=1)\n",
    "\n",
    "feature_eng = FunctionTransformer(feature_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess for numerical, ordinal, and nominal features\n",
    "# Well, not really tho. \n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "ord_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "nom_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipe, num_var),\n",
    "    ('ord', ord_pipe, ord_var)\n",
    "    # ('nom', nom_pipe, nom_var)\n",
    "])\n",
    "\n",
    "\n",
    "# full_pipe = Pipeline([\n",
    "#     ('eng', feature_eng),\n",
    "#     ('pre', preprocess)\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ed80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom scorer\n",
    "def rmse_log(yt, yp):\n",
    "  lt = np.log1p(yt)\n",
    "  lp = np.log1p(yp)\n",
    "  return np.sqrt(np.mean((lt-lp)**2))\n",
    "\n",
    "rmse_log_scorer = make_scorer(rmse_log, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a04619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of regression models\n",
    "basic_models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    ElasticNet(random_state=42),\n",
    "    KNeighborsRegressor(),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    HistGradientBoostingRegressor(random_state=42),\n",
    "    XGBRegressor(random_state=42),\n",
    "    LGBMRegressor(random_state=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db7e18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling function\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def modeling(models=basic_models, eng=False):\n",
    "    res = []\n",
    "    for model in models:\n",
    "        if eng:\n",
    "            full_pipe = Pipeline([\n",
    "                ('eng', feature_eng),\n",
    "                ('pre', preprocess),\n",
    "                ('reg', model)\n",
    "            ])\n",
    "            print(\"featuring!\")\n",
    "        else: \n",
    "            full_pipe = Pipeline([\n",
    "                ('pre', preprocess),\n",
    "                ('reg', model)\n",
    "            ])\n",
    "            \n",
    "        print(model)      \n",
    "        grid_search = GridSearchCV(estimator=full_pipe, param_grid = {}, cv=kf, \n",
    "                                    scoring = {'rmse':'neg_root_mean_squared_error',\n",
    "                                                'msle2':'neg_root_mean_squared_log_error',\n",
    "                                                'msle1': rmse_log_scorer}, \n",
    "                                    refit = 'msle2', verbose=0, n_jobs=-1)\n",
    "            \n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        # return grid_search.predict(X)\n",
    "            \n",
    "        result = {\n",
    "                'model': type(model).__name__,\n",
    "                'msle1': -grid_search.cv_results_['mean_test_msle1'][0],\n",
    "                'rmse': -grid_search.cv_results_['mean_test_rmse'][0],\n",
    "                'msle2': -grid_search.cv_results_['mean_test_msle2'][0],\n",
    "                'time': grid_search.cv_results_['mean_fit_time'][0],\n",
    "                'params': model.get_params()\n",
    "            }\n",
    "            \n",
    "        res.append(result)\n",
    "    res = pd.DataFrame(res)\n",
    "    res.set_index('model', inplace=True)\n",
    "    return pd.DataFrame(res), grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3308148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\OneDrive\\Lepas Kuliah\\Projects\\house-price-prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(random_state=42)\n",
      "Lasso(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\OneDrive\\Lepas Kuliah\\Projects\\house-price-prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\ACER\\OneDrive\\Lepas Kuliah\\Projects\\house-price-prediction\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+09, tolerance: 9.208e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(random_state=42)\n",
      "KNeighborsRegressor()\n",
      "RandomForestRegressor(random_state=42)\n",
      "HistGradientBoostingRegressor(random_state=42)\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "             n_jobs=None, num_parallel_tree=None, ...)\n",
      "LGBMRegressor(random_state=42)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3300\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 180921.195890\n"
     ]
    }
   ],
   "source": [
    "# First modeling (51.9s)\n",
    "res_basic, cv_basic = modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6143301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuring!\n",
      "LinearRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\OneDrive\\Lepas Kuliah\\Projects\\house-price-prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuring!\n",
      "Ridge(random_state=42)\n",
      "featuring!\n",
      "Lasso(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\OneDrive\\Lepas Kuliah\\Projects\\house-price-prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\ACER\\OneDrive\\Lepas Kuliah\\Projects\\house-price-prediction\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+09, tolerance: 9.208e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featuring!\n",
      "ElasticNet(random_state=42)\n",
      "featuring!\n",
      "KNeighborsRegressor()\n",
      "featuring!\n",
      "RandomForestRegressor(random_state=42)\n",
      "featuring!\n",
      "HistGradientBoostingRegressor(random_state=42)\n",
      "featuring!\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "             n_jobs=None, num_parallel_tree=None, ...)\n",
      "featuring!\n",
      "LGBMRegressor(random_state=42)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3300\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score 180921.195890\n"
     ]
    }
   ],
   "source": [
    "# Second modeling (39.7s)\n",
    "res_eng, cv_eng = modeling(eng=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d546be21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msle1</th>\n",
       "      <th>rmse</th>\n",
       "      <th>msle2</th>\n",
       "      <th>time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.138314</td>\n",
       "      <td>29202.882384</td>\n",
       "      <td>0.138314</td>\n",
       "      <td>0.929727</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.138626</td>\n",
       "      <td>29178.515451</td>\n",
       "      <td>0.138626</td>\n",
       "      <td>0.947151</td>\n",
       "      <td>{'categorical_features': 'from_dtype', 'early_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.141867</td>\n",
       "      <td>31259.181250</td>\n",
       "      <td>0.141867</td>\n",
       "      <td>0.754835</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.146925</td>\n",
       "      <td>30268.857053</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>4.556262</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.152255</td>\n",
       "      <td>34939.789808</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>0.143919</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.174310</td>\n",
       "      <td>39338.024485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113706</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.174396</td>\n",
       "      <td>39354.855969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.196038</td>\n",
       "      <td>37968.769895</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.089308</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.197946</td>\n",
       "      <td>41285.438737</td>\n",
       "      <td>0.197946</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  msle1          rmse     msle2      time  \\\n",
       "model                                                                       \n",
       "LGBMRegressor                  0.138314  29202.882384  0.138314  0.929727   \n",
       "HistGradientBoostingRegressor  0.138626  29178.515451  0.138626  0.947151   \n",
       "XGBRegressor                   0.141867  31259.181250  0.141867  0.754835   \n",
       "RandomForestRegressor          0.146925  30268.857053  0.146925  4.556262   \n",
       "ElasticNet                     0.152255  34939.789808  0.152255  0.143919   \n",
       "Lasso                          0.174310  39338.024485       NaN  0.113706   \n",
       "LinearRegression               0.174396  39354.855969       NaN  0.098189   \n",
       "Ridge                          0.196038  37968.769895  0.196038  0.089308   \n",
       "KNeighborsRegressor            0.197946  41285.438737  0.197946  0.060095   \n",
       "\n",
       "                                                                          params  \n",
       "model                                                                             \n",
       "LGBMRegressor                  {'boosting_type': 'gbdt', 'class_weight': None...  \n",
       "HistGradientBoostingRegressor  {'categorical_features': 'from_dtype', 'early_...  \n",
       "XGBRegressor                   {'objective': 'reg:squarederror', 'base_score'...  \n",
       "RandomForestRegressor          {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
       "ElasticNet                     {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...  \n",
       "Lasso                          {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...  \n",
       "LinearRegression               {'copy_X': True, 'fit_intercept': True, 'n_job...  \n",
       "Ridge                          {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...  \n",
       "KNeighborsRegressor            {'algorithm': 'auto', 'leaf_size': 30, 'metric...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msle1</th>\n",
       "      <th>rmse</th>\n",
       "      <th>msle2</th>\n",
       "      <th>time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.138314</td>\n",
       "      <td>29202.882384</td>\n",
       "      <td>0.138314</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>{'boosting_type': 'gbdt', 'class_weight': None...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.138626</td>\n",
       "      <td>29178.515451</td>\n",
       "      <td>0.138626</td>\n",
       "      <td>0.993028</td>\n",
       "      <td>{'categorical_features': 'from_dtype', 'early_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.141867</td>\n",
       "      <td>31259.181250</td>\n",
       "      <td>0.141867</td>\n",
       "      <td>0.978966</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.146925</td>\n",
       "      <td>30268.857053</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>4.372874</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.152255</td>\n",
       "      <td>34939.789808</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>0.075942</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.174310</td>\n",
       "      <td>39338.024485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129799</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.174396</td>\n",
       "      <td>39354.855969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098413</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.196038</td>\n",
       "      <td>37968.769895</td>\n",
       "      <td>0.196038</td>\n",
       "      <td>0.066914</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.197946</td>\n",
       "      <td>41285.438737</td>\n",
       "      <td>0.197946</td>\n",
       "      <td>0.054513</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  msle1          rmse     msle2      time  \\\n",
       "model                                                                       \n",
       "LGBMRegressor                  0.138314  29202.882384  0.138314  0.587000   \n",
       "HistGradientBoostingRegressor  0.138626  29178.515451  0.138626  0.993028   \n",
       "XGBRegressor                   0.141867  31259.181250  0.141867  0.978966   \n",
       "RandomForestRegressor          0.146925  30268.857053  0.146925  4.372874   \n",
       "ElasticNet                     0.152255  34939.789808  0.152255  0.075942   \n",
       "Lasso                          0.174310  39338.024485       NaN  0.129799   \n",
       "LinearRegression               0.174396  39354.855969       NaN  0.098413   \n",
       "Ridge                          0.196038  37968.769895  0.196038  0.066914   \n",
       "KNeighborsRegressor            0.197946  41285.438737  0.197946  0.054513   \n",
       "\n",
       "                                                                          params  \n",
       "model                                                                             \n",
       "LGBMRegressor                  {'boosting_type': 'gbdt', 'class_weight': None...  \n",
       "HistGradientBoostingRegressor  {'categorical_features': 'from_dtype', 'early_...  \n",
       "XGBRegressor                   {'objective': 'reg:squarederror', 'base_score'...  \n",
       "RandomForestRegressor          {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...  \n",
       "ElasticNet                     {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...  \n",
       "Lasso                          {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...  \n",
       "LinearRegression               {'copy_X': True, 'fit_intercept': True, 'n_job...  \n",
       "Ridge                          {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...  \n",
       "KNeighborsRegressor            {'algorithm': 'auto', 'leaf_size': 30, 'metric...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res_basic.sort_values('msle1', ascending=True), \n",
    "        res_eng.sort_values('msle1', ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b816de",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "- Feature engineering is useless, even in linear model (?)\n",
    "- Maybe, because the one I implemented isn't that important, while the other features already have a great effect\n",
    "- Even a likely important new feature is a useless? whoah, i'm surprised LOL. \n",
    "- Anyway, the best 4 are tree models, followed by 4 linear models, and the last one is KN regression\n",
    "- Elastic net, a linear regression model with L1 & L2 penalty got a pretty good result following the tree models\n",
    "-  The best model is LGBM Regressor, with 0.138 MSLE and 29203 RMSE, so the mean prediction error is around 29k (note that minimum saleprice is ~35k, median saleprice is ~163k) which isn't really good prediction in average (~18% error, based on a median price), let alone for a cheaper house. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
